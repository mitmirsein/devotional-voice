/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// main.ts
var main_exports = {};
__export(main_exports, {
  default: () => VoiceWritingPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian3 = require("obsidian");

// src/recorder.ts
var MicrophoneRecorder = class {
  constructor() {
    this.mediaRecorder = null;
    this.audioChunks = [];
  }
  async startRecording() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      this.mediaRecorder = new MediaRecorder(stream);
      this.audioChunks = [];
      this.mediaRecorder.addEventListener("dataavailable", (event) => {
        this.audioChunks.push(event.data);
      });
      this.mediaRecorder.start();
    } catch (error) {
      console.error("Error starting recording:", error);
      throw error;
    }
  }
  async stopRecording() {
    return new Promise((resolve, reject) => {
      if (!this.mediaRecorder) {
        reject(new Error("No active recording"));
        return;
      }
      this.mediaRecorder.addEventListener("stop", () => {
        var _a;
        const audioBlob = new Blob(this.audioChunks, { type: "audio/webm" });
        this.audioChunks = [];
        (_a = this.mediaRecorder) == null ? void 0 : _a.stream.getTracks().forEach((track) => track.stop());
        this.mediaRecorder = null;
        resolve(audioBlob);
      });
      this.mediaRecorder.stop();
    });
  }
  isRecording() {
    var _a;
    return ((_a = this.mediaRecorder) == null ? void 0 : _a.state) === "recording";
  }
};

// src/transcription.ts
var import_obsidian = require("obsidian");
var TranscriptionService = class {
  async transcribe(audioBlob, apiKey, language, serviceProvider) {
    if (!apiKey) {
      new import_obsidian.Notice("API Key is missing. Please set it in settings.");
      throw new Error("API Key missing");
    }
    const arrayBuffer = await audioBlob.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    const boundary = "----ObsidianVoiceWritingBoundary" + Date.now();
    const body = await this.createFormData(buffer, "recording.webm", boundary, language, serviceProvider);
    const url = serviceProvider === "openai" ? "https://api.openai.com/v1/audio/transcriptions" : "https://api.groq.com/openai/v1/audio/transcriptions";
    const model = serviceProvider === "openai" ? "whisper-1" : "whisper-large-v3";
    const params = {
      url,
      method: "POST",
      headers: {
        "Content-Type": `multipart/form-data; boundary=${boundary}`,
        "Authorization": `Bearer ${apiKey}`
      },
      body
    };
    try {
      const response = await (0, import_obsidian.requestUrl)(params);
      if (response.status !== 200) {
        console.error("Transcription failed:", response.json);
        throw new Error(`Transcription failed: ${response.status}`);
      }
      return { text: response.json.text };
    } catch (error) {
      console.error("Transcription error:", error);
      new import_obsidian.Notice("Transcription failed. Check console for details.");
      throw error;
    }
  }
  async createFormData(fileBuffer, fileName, boundary, language, provider) {
    const parts = [];
    const model = provider === "openai" ? "whisper-1" : "whisper-large-v3";
    parts.push(Buffer.from(`--${boundary}\r
`));
    parts.push(Buffer.from(`Content-Disposition: form-data; name="file"; filename="${fileName}"\r
`));
    parts.push(Buffer.from(`Content-Type: audio/webm\r
\r
`));
    parts.push(fileBuffer);
    parts.push(Buffer.from(`\r
`));
    parts.push(Buffer.from(`--${boundary}\r
`));
    parts.push(Buffer.from(`Content-Disposition: form-data; name="model"\r
\r
`));
    parts.push(Buffer.from(`${model}\r
`));
    if (language && language !== "auto") {
      parts.push(Buffer.from(`--${boundary}\r
`));
      parts.push(Buffer.from(`Content-Disposition: form-data; name="language"\r
\r
`));
      parts.push(Buffer.from(`${language}\r
`));
    }
    parts.push(Buffer.from(`--${boundary}--\r
`));
    return Buffer.concat(parts).buffer;
  }
};

// src/modals.ts
var import_obsidian2 = require("obsidian");
var ProcessingModal = class extends import_obsidian2.Modal {
  constructor(app) {
    super(app);
  }
  onOpen() {
    const { contentEl } = this;
    contentEl.empty();
    contentEl.addClass("voice-writing-processing-modal");
    contentEl.createEl("h2", { text: "\u2728 Processing Audio..." });
    const spinner = contentEl.createDiv({ cls: "voice-writing-spinner" });
    spinner.createDiv({ cls: "double-bounce1" });
    spinner.createDiv({ cls: "double-bounce2" });
    contentEl.createEl("p", { text: "Transcribing your voice..." });
  }
  onClose() {
    const { contentEl } = this;
    contentEl.empty();
  }
};
var QuickOptionModal = class extends import_obsidian2.Modal {
  constructor(app, currentLanguage, currentService, onSelect) {
    super(app);
    this.currentLanguage = currentLanguage;
    this.currentService = currentService;
    this.onSelect = onSelect;
  }
  onOpen() {
    const { contentEl } = this;
    contentEl.empty();
    contentEl.createEl("h2", { text: "Voice Writing Options" });
    let tempLanguage = this.currentLanguage;
    let tempService = this.currentService;
    new import_obsidian2.Setting(contentEl).setName("Language").setDesc("Select audio language").addDropdown(
      (drop) => drop.addOption("auto", "Auto Detect").addOption("en", "English").addOption("ko", "Korean").addOption("ja", "Japanese").setValue(tempLanguage).onChange((value) => tempLanguage = value)
    );
    new import_obsidian2.Setting(contentEl).setName("Service").setDesc("Transcription provider").addDropdown(
      (drop) => drop.addOption("openai", "OpenAI Whisper").addOption("groq", "Groq (Fast)").setValue(tempService).onChange((value) => tempService = value)
    );
    new import_obsidian2.Setting(contentEl).addButton(
      (btn) => btn.setButtonText("Apply").setCta().onClick(() => {
        this.onSelect(tempLanguage, tempService);
        this.close();
      })
    );
  }
  onClose() {
    this.contentEl.empty();
  }
};

// main.ts
var DEFAULT_SETTINGS = {
  apiKey: "",
  language: "auto",
  serviceProvider: "openai"
};
var VoiceWritingPlugin = class extends import_obsidian3.Plugin {
  async onload() {
    await this.loadSettings();
    this.recorder = new MicrophoneRecorder();
    this.transcriptionService = new TranscriptionService();
    this.ribbonIconEl = this.addRibbonIcon("mic", "Voice Writing", (evt) => {
      this.toggleRecording();
    });
    this.ribbonIconEl.addClass("voice-writing-ribbon");
    this.statusBarItem = this.addStatusBarItem();
    this.updateStatusBar("Idle");
    this.statusBarItem.onClickEvent(() => {
      this.toggleRecording();
    });
    this.addCommand({
      id: "start-recording",
      name: "Start Recording",
      callback: () => this.startRecording()
    });
    this.addCommand({
      id: "stop-recording",
      name: "Stop Recording",
      callback: () => this.stopRecording()
    });
    this.addCommand({
      id: "quick-options",
      name: "Quick Options",
      callback: () => {
        new QuickOptionModal(this.app, this.settings.language, this.settings.serviceProvider, async (lang, service) => {
          this.settings.language = lang;
          this.settings.serviceProvider = service;
          await this.saveSettings();
          new import_obsidian3.Notice(`Settings saved: ${service} / ${lang}`);
        }).open();
      }
    });
    this.addSettingTab(new VoiceWritingSettingTab(this.app, this));
  }
  async toggleRecording() {
    if (this.recorder.isRecording()) {
      await this.stopRecording();
    } else {
      await this.startRecording();
    }
  }
  async startRecording() {
    try {
      await this.recorder.startRecording();
      new import_obsidian3.Notice("\u{1F399}\uFE0F Recording started...");
      this.ribbonIconEl.addClass("voice-writing-recording");
      this.updateStatusBar("Recording...");
    } catch (error) {
      new import_obsidian3.Notice("Failed to start recording: " + error);
    }
  }
  async stopRecording() {
    try {
      const blob = await this.recorder.stopRecording();
      this.ribbonIconEl.removeClass("voice-writing-recording");
      this.updateStatusBar("Processing...");
      const processingModal = new ProcessingModal(this.app);
      processingModal.open();
      const fileName = `recording-${Date.now()}.webm`;
      const arrayBuffer = await blob.arrayBuffer();
      await this.app.vault.createBinary(fileName, new Uint8Array(arrayBuffer));
      try {
        const result = await this.transcriptionService.transcribe(
          blob,
          this.settings.apiKey,
          this.settings.language,
          this.settings.serviceProvider
        );
        processingModal.close();
        new import_obsidian3.Notice("\u2705 Transcription complete!");
        this.updateStatusBar("Idle");
        const activeView = this.app.workspace.getActiveViewOfType(import_obsidian3.MarkdownView);
        if (activeView) {
          const editor = activeView.editor;
          const template = `![[${fileName}]]

${result.text}
`;
          editor.replaceSelection(template);
        } else {
          new import_obsidian3.Notice("Text copied to clipboard (No active editor)");
          navigator.clipboard.writeText(result.text);
        }
      } catch (transcriptionError) {
        processingModal.close();
        new import_obsidian3.Notice("\u274C Transcription failed. Audio saved.");
        console.error(transcriptionError);
        this.updateStatusBar("Error");
        const activeView = this.app.workspace.getActiveViewOfType(import_obsidian3.MarkdownView);
        if (activeView) {
          activeView.editor.replaceSelection(`![[${fileName}]]
`);
        }
      }
    } catch (error) {
      new import_obsidian3.Notice("Failed to stop recording: " + error);
      this.updateStatusBar("Error");
    }
  }
  updateStatusBar(text) {
    this.statusBarItem.setText(`Mic: ${text}`);
    if (text === "Recording...") {
      this.statusBarItem.addClass("voice-writing-recording");
    } else {
      this.statusBarItem.removeClass("voice-writing-recording");
    }
  }
  onunload() {
  }
  async loadSettings() {
    this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
  }
  async saveSettings() {
    await this.saveData(this.settings);
  }
};
var VoiceWritingSettingTab = class extends import_obsidian3.PluginSettingTab {
  constructor(app, plugin) {
    super(app, plugin);
    this.plugin = plugin;
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    containerEl.createEl("h2", { text: "Voice Writing Settings" });
    new import_obsidian3.Setting(containerEl).setName("Service Provider").setDesc("Choose between OpenAI (Best quality) or Groq (Fastest)").addDropdown((drop) => drop.addOption("openai", "OpenAI").addOption("groq", "Groq").setValue(this.plugin.settings.serviceProvider).onChange(async (value) => {
      this.plugin.settings.serviceProvider = value;
      await this.plugin.saveSettings();
      this.display();
    }));
    new import_obsidian3.Setting(containerEl).setName("API Key").setDesc(`Enter your ${this.plugin.settings.serviceProvider === "openai" ? "OpenAI" : "Groq"} API Key`).addText((text) => text.setPlaceholder("sk-...").setValue(this.plugin.settings.apiKey).onChange(async (value) => {
      this.plugin.settings.apiKey = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian3.Setting(containerEl).setName("Default Language").setDesc('Language code for transcription (e.g., en, ko, ja). Use "auto" for auto-detection.').addText((text) => text.setPlaceholder("auto").setValue(this.plugin.settings.language).onChange(async (value) => {
      this.plugin.settings.language = value;
      await this.plugin.saveSettings();
    }));
  }
};
